{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiJ2706/snake_game_reinforcement_learning/blob/main/SnakeRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SNAKE GAME (ft. reinforcement learning)\n",
        "\n",
        "This is an ML model designed to play the popular [snake game](https://g.co/kgs/HGzzUC). It utilizes a Q-learning algorithm to learn the game. Essentially, in Q-learning, the game is composed of 2 pieces: an agent, which is the main \"character\" or \"game piece\" which plays the game, and the environment, where the agent exists. The algorithm updates a set of weights which dictate how the agent reacts in each possible state in the game. The algorithm assigns a reward for each action that can be taken at each state. This reward is used to determine the best action at each state, and update the weights accordingly.\n",
        "\n",
        "How the algorithm works:\n",
        "\n",
        "1. at each state we either choose the best action by looking at the weights, or choose a random action. We then update the weights at that state depending on the outcome, using the Q-learning formula.\n",
        "2. if the game ends, it is reset and the next iteration of learning begins, with the updated weights. The position of the snake and the apple is randomized. The weights keep getting tuned over time this way.\n",
        "3. if the game does not end, the next turn begins and step 1 s repeated until step 2 occurs."
      ],
      "metadata": {
        "id": "QN_czbqjX9iB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: import libraries"
      ],
      "metadata": {
        "id": "3khVP4-laZhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS_dgQWzlGf1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "from random import choice\n",
        "from random import uniform\n",
        "from random import shuffle\n",
        "from itertools import combinations\n",
        "from copy import deepcopy\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: configure hyperparameters\n",
        "\n",
        "There are several hyperparameters needed to configure the model.\n",
        "\n",
        "* n: the size of the grid. This affects the number of states in the game. Thus the other parameters need to be configured around it accordingly.\n",
        "* epsilon: the chance that a random action is taken over the best action. This helps the agent learn, especially at the beginning of training, as all weights are initially 0.\n",
        "* lr: the learning rate, affects the impact of the reward on the tuning of weights\n",
        "* discount: how much to consider the outcome of the best action from the next state\n",
        "* epochs: number of training iterations to perform"
      ],
      "metadata": {
        "id": "oidE138Ral6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 7\n",
        "\n",
        "epsilon = 0.2\n",
        "\n",
        "lr = 0.13\n",
        "\n",
        "discount = 0.6\n",
        "\n",
        "epochs = 250000"
      ],
      "metadata": {
        "id": "x1WNURZQ3Uel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all 4 directions for moving the snake\n",
        "# CONVENTION: L U R D\n",
        "\n",
        "dirs = ((0, -1), (-1, 0), (0, 1), (1, 0))\n",
        "\n",
        "all_apples = [(x, y) for x in range(1, n - 1) for y in range(1, n - 1)]"
      ],
      "metadata": {
        "id": "SvgLMwrm44JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: grid setup"
      ],
      "metadata": {
        "id": "IBNEjdN3cllK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Ild3Z3qlM5"
      },
      "outputs": [],
      "source": [
        "grid = [[-1 for i in range(n)]] + [[-1] + [0 for i in range(n - 2)] + [-1] for i in range(n - 2)] + [[-1 for i in range(n)]]\n",
        "\n",
        "shuffle(all_apples)\n",
        "apple_pos = all_apples[0]\n",
        "radius = ([*range(1, apple_pos[0] - 1), *range(apple_pos[0] + 1, n - 1)], \n",
        "          [*range(1, apple_pos[1] - 1), *range(apple_pos[1] + 1, n - 1)])\n",
        "snake_pos = (choice(radius[0]), choice(radius[1]))\n",
        "\n",
        "grid[apple_pos[0]][apple_pos[1]] = 1\n",
        "grid[snake_pos[0]][snake_pos[1]] = -1\n",
        "\n",
        "original_snake_pos = deepcopy(snake_pos)\n",
        "original_apple_pos = deepcopy(apple_pos)\n",
        "\n",
        "snake = [snake_pos]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: building states\n",
        "\n",
        "In the case of the snake game, we have the following convention for states:\n",
        "\n",
        "* 1 represents the apple\n",
        "* -1 represents a square which would end the game, e.g. the snake's tail or a wall\n",
        "* 0 is an empty space\n",
        "\n",
        "Since the snake can only move up, left, down, or right, at each state we only care about the square above, to the left, to the right, and below the snake's head. We also need to keep in mind where the head is and where the apple is in order to force the agent towards the apple. Thus the states are constructed as such:\n",
        "\n",
        "(square left, square above, square right, square below, apple x, apple y, head x, head y)\n",
        "\n",
        "The numebr of states is the number of possible (left, up, right, down) combinations * the number of apple positions * the number of head positions. This can grow extremely quickly with n."
      ],
      "metadata": {
        "id": "ALCY3iwncn-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = list(set(map(lambda x: tuple(map(lambda y: 0 if y % 2 == 0 else -1, x)), combinations(range(8), 4))))\n",
        "\n",
        "apple_states = []\n",
        "\n",
        "for s in states:\n",
        "    apple_states += [tuple(1 if j == i else s[i] for i in range(len(s))) for j in range(len(s))]\n",
        "\n",
        "states += apple_states\n",
        "\n",
        "for i in range(2):\n",
        "    all_states = list(map(lambda x: [(*x, *a) for a in all_apples], states))\n",
        "\n",
        "    states = []\n",
        "\n",
        "    for s in all_states:\n",
        "        states += s\n",
        "\n",
        "states = {s: [0 for i in range(4)] for s in states}"
      ],
      "metadata": {
        "id": "3vRPbXRt5db2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: reinforcement learning methods\n",
        "\n",
        "The following methods are for determining the rewards and updating the q table containing the states.\n",
        "\n",
        "Essentially, a positive reward is given for getting to the apple or getting closer to it, a negative reward is given for getting farther from the apple or hitting a wall or the snake's tail. "
      ],
      "metadata": {
        "id": "HXPjYFdSe877"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur19M0S1uWCs"
      },
      "outputs": [],
      "source": [
        "def reward(s, a):\n",
        "    global snake, apple_pos\n",
        "    head = snake[0]\n",
        "    if s[a] == 1:\n",
        "        return 100\n",
        "    elif s[a] == 0:\n",
        "        new_head = (head[0] + dirs[a][0], head[1] + dirs[a][1])\n",
        "        old_apple_dist = ((apple_pos[0] - head[0]), (apple_pos[1] - head[1]))\n",
        "        new_apple_dist = ((apple_pos[0] - new_head[0]), (apple_pos[1] - new_head[1]))\n",
        "        if old_apple_dist[0] < new_apple_dist[0] or old_apple_dist[1] < new_apple_dist[1]:\n",
        "            return -10\n",
        "        else:\n",
        "            return 1\n",
        "    else:\n",
        "        return -100\n",
        "\n",
        "def Q(s, a):\n",
        "    global snake, grid, states, lr, discount, apple_pos\n",
        "    if type(a) is range:\n",
        "        return [Q(s, x) for x in a]\n",
        "    else:\n",
        "        head = (snake[0][0] + dirs[a][0], snake[0][1] + dirs[a][1])\n",
        "        try:\n",
        "            new_state = (grid[head[0]][head[1] - 1], \n",
        "                         grid[head[0] - 1][head[1]], \n",
        "                         grid[head[0]][head[1] + 1], \n",
        "                         grid[head[0] + 1][head[1]], *apple_pos, *head)\n",
        "            return lr * (reward(s, a) + discount * max(states[new_state]) - states[s][a])\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "def try_reference_spot(x, y):\n",
        "    global grid\n",
        "    try:\n",
        "        z = grid[x][y]\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def update_q_table(random=True):\n",
        "    global snake, grid, states, apple_pos, epsilon\n",
        "    x = uniform(0, 1) if random else 0\n",
        "    head = snake[0]\n",
        "    state = (grid[head[0]][head[1] - 1], \n",
        "             grid[head[0] - 1][head[1]], \n",
        "             grid[head[0]][head[1] + 1], \n",
        "             grid[head[0] + 1][head[1]], *apple_pos, *head)\n",
        "    if x < epsilon and random:\n",
        "        move = randint(0, 3)\n",
        "        while not try_reference_spot(snake[0][0] + dirs[move][0], snake[0][1] + dirs[move][1]):\n",
        "            move = randint(0, 3)\n",
        "        states[state][move] = (1 - lr) * states[state][move] + Q(state, move)\n",
        "        return move\n",
        "    else:\n",
        "        move = max(enumerate(states[state], 0), key=lambda x: x[1])[0]\n",
        "        states[state][move] = (1 - lr) * states[state][move] + Q(state, move)\n",
        "        return move\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: game function\n",
        "\n",
        "This is the main loop for the game which handles all the game mechanics."
      ],
      "metadata": {
        "id": "jpTNvR8RgIum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def move_snake(snake, dir):\n",
        "    return list(filter(lambda x: x is not None, [(snake[0][0] + dir[0], snake[0][1] + dir[1])] + \\\n",
        "            list(map(lambda x: snake[x[0]] if x[0] < len(snake) - 1 else None, \\\n",
        "                     enumerate(snake, 0)))))\n",
        "\n",
        "def pretty_print_grid(grid):\n",
        "    global n, snake\n",
        "    for i, y in enumerate(grid, 0):\n",
        "        for j, xy in enumerate(y, 0):\n",
        "            if i == 0 or i == n - 1:\n",
        "                print(\"w\\t\", end=\"\")\n",
        "            elif j == 0 or j == n - 1:\n",
        "                print(\"w\\t\", end=\"\")\n",
        "            elif xy == -1 and i == snake[0][0] and j == snake[0][1]:\n",
        "                print(\"h\\t\", end=\"\")\n",
        "            elif xy == 1:\n",
        "                print(\"A\\t\", end=\"\")\n",
        "            elif xy == -1:\n",
        "                print(\"s\\t\", end=\"\")\n",
        "            else:\n",
        "                print(f\" \\t\", end=\"\")\n",
        "        print()\n",
        "\n",
        "def play_game(print_out=False, learning_phase=True):\n",
        "    global snake, grid, apple_pos, original_apple_pos, original_snake_pos, dirs\n",
        "    alive = True\n",
        "    game_length = 0\n",
        "    snake_length = 0\n",
        "\n",
        "    while alive:\n",
        "        move = update_q_table(random=learning_phase)\n",
        "        snake = move_snake(snake, dirs[move])\n",
        "        if grid[snake[0][0]][snake[0][1]] == -1:\n",
        "            shuffle(all_apples)\n",
        "            apple_pos = all_apples[0]\n",
        "            snake_length = len(snake)\n",
        "            radius = ([*range(1, apple_pos[0] - 1), *range(apple_pos[0] + 1, n - 1)], \n",
        "                    [*range(1, apple_pos[1] - 1), *range(apple_pos[1] + 1, n - 1)])\n",
        "            snake_pos = (choice(radius[0]), choice(radius[1]))\n",
        "            snake = [snake_pos]\n",
        "            alive = False\n",
        "        elif grid[snake[0][0]][snake[0][1]] == 1:\n",
        "            radius = ([*range(1, snake[0][0] - 1), *range(snake[0][0] + 1, n - 1)], \n",
        "                        [*range(1, snake[0][1] - 1), *range(snake[0][1] + 1, n - 1)])\n",
        "            new_x = choice(radius[0])\n",
        "            new_y = choice(radius[1])\n",
        "            while grid[new_x][new_y] != 0:\n",
        "                new_x = choice(radius[0])\n",
        "                new_y = choice(radius[1])\n",
        "            apple_pos = (new_x, new_y)\n",
        "            tail = snake[-1]\n",
        "            state = (grid[tail[0]][tail[1] - 1], grid[tail[0] - 1][tail[1]], grid[tail[0]][tail[1] + 1], grid[tail[0] + 1][tail[1]])\n",
        "            for i in range(4):\n",
        "                if state[i] == 0:\n",
        "                    grid[tail[0] + dirs[i][0]][tail[1] + dirs[i][1]] = -1\n",
        "                    new_state = (grid[snake[0][0]][snake[0][1] - 1], grid[snake[0][0] - 1][snake[0][1]], grid[snake[0][0]][snake[0][1] + 1], grid[snake[0][0] + 1][snake[0][1]])\n",
        "                    if new_state == (-1, -1, -1, -1): continue\n",
        "                    snake.append((tail[0] + dirs[i][0], tail[1] + dirs[i][1]))\n",
        "                    break\n",
        "        grid = [[-1 for i in range(n)]] + [[-1] + [0 for i in range(n - 2)] + [-1] for i in range(n - 2)] + [[-1 for i in range(n)]]\n",
        "        grid[apple_pos[0]][apple_pos[1]] = 1\n",
        "        if not learning_phase: print(snake)\n",
        "        if alive:\n",
        "            game_length += 1\n",
        "            for s in snake:\n",
        "                grid[s[0]][s[1]] = -1\n",
        "            if print_out: \n",
        "                pretty_print_grid(grid)\n",
        "        else:\n",
        "            if learning_phase: \n",
        "                print(\"Length of game:\", game_length, \"| Length of snake:\", snake_length, \"| Apples found:\", snake_length - 1)\n"
      ],
      "metadata": {
        "id": "xbrPsfW15WmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: training"
      ],
      "metadata": {
        "id": "uRclTz4ZgP9H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPq3WthI3TcR"
      },
      "outputs": [],
      "source": [
        "for i in range(epochs):\n",
        "    print(i, end=\" \")\n",
        "    play_game(learning_phase=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: play the game!\n",
        "\n",
        "The board is pretty printed for convenience.\n",
        "\n",
        "* A: apple\n",
        "* h: snake head\n",
        "* s: snake tail\n",
        "* w: wall"
      ],
      "metadata": {
        "id": "6R19XLOsgdEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "play_game(print_out=True, learning_phase=False)\n",
        "print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "D3xr_KJzn0yU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SnakeRL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKTBrN2tes62ieVWuBAIOV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}